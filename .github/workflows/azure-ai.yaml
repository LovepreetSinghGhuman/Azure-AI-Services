name: Azure ML Job Pipeline

on: 
  workflow_dispatch:

env:
  GROUP: mlops-demo
  WORKSPACE: singh-lovepreet-ls
  LOCATION: westeurope
  COMPUTE_NAME: cli-created-machine

jobs:
  azure-pipeline:
    runs-on: ubuntu-24.04
    steps:
      - name: Check out code repository
        uses: actions/checkout@v4

      - name: Azure login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Azure -- Setup ML extension and defaults
        uses: azure/CLI@v2.1.0
        with:
          azcliversion: 2.64.0
          inlineScript: |
            az extension add --name ml -y
            az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION

      - name: Azure -- Check if compute exists
        id: check_compute
        uses: azure/CLI@v2.1.0
        with:
          azcliversion: 2.64.0
          inlineScript: |
            if az ml compute show --name $COMPUTE_NAME &> /dev/null; then
              echo "exists=true" >> $GITHUB_OUTPUT
            else
              echo "exists=false" >> $GITHUB_OUTPUT
            fi

      - name: Azure -- Create compute if not exists
        if: steps.check_compute.outputs.exists == 'false'
        uses: azure/CLI@v2.1.0
        with:
          azcliversion: 2.64.0
          inlineScript: |
            az ml compute create --file ./environment/compute.yaml

      - name: Azure -- Start compute (cold-start compliant)
        # Always try to start, ignore error if already running
        uses: azure/CLI@v2.1.0
        with:
          azcliversion: 2.64.0
          inlineScript: |
            az ml compute start --name $COMPUTE_NAME
        continue-on-error: true

      - name: Azure -- Register combined environment
        uses: azure/CLI@v2.1.0
        with:
          azcliversion: 2.64.0
          inlineScript: |
            az ml environment create --file ./environment/combined.yaml

      - name: Azure -- Submit animals classification job
        uses: azure/CLI@v2.1.0
        with:
          azcliversion: 2.64.0
          inlineScript: |
            az ml job create --file ./pipelines/animals-classification.yaml \
              --stream \
              --set name=animals-classification-${{ github.sha }}-${{ github.run_id }}

      - name: Azure -- Stop compute machine
        uses: azure/CLI@v2.1.0
        with:
          azcliversion: 2.64.0
          inlineScript: |
            az ml compute stop --name $COMPUTE_NAME
        continue-on-error: true

  download:
    needs: azure-pipeline
    runs-on: ubuntu-24.04
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Azure -- Download Model
        uses: azure/CLI@v2.1.0
        with:
          azcliversion: 2.64.0
          inlineScript: |
            az extension add --name ml -y
            az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
            VERSION=$(az ml model list -n animal-classification --query "[0].version" -o tsv)
            az ml model download -n animal-classification -v $VERSION -p ./model --overwrite

      - name: Docker -- Upload API code from Inference
        uses: actions/upload-artifact@v4.3.3
        with:
          name: docker-config
          path: inference

  deploy:
    needs: download
    runs-on: self-hosted
    steps:
      - name: Docker -- Gather Tags
        id: docker-meta-data
        uses: docker/metadata-action@v5.5.1
        with:
          images: |
            ghcr.io/singhlovepreet/mlops-animals-api
          tags: |
            type=ref,event=branch
            type=sha

      - name: Docker -- Login to GHCR
        uses: docker/login-action@v3.2.0
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Docker -- Download API Code for Inference
        uses: actions/download-artifact@v4.1.7
        with:
          name: docker-config
          path: inference

      - name: Docker Build and push
        id: docker_build
        uses: docker/build-push-action@v5.3.0
        with:
          context: ./inference
          push: true
          tags: ${{ steps.docker-meta-data.outputs.tags }}